from typing import List, Dict, Optional
from enum import Enum
import numpy as np

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch_geometric as gtorch
import torch_geometric.nn as gnn

from rlkit.torch.core import PyTorchModule
import rlkit.torch.pytorch_util as ptu

from .graph_utils import Node, get_inner_edge_keys



import math
from typing import Dict, List, Optional, Union

import torch
import torch.nn.functional as F
from torch import Tensor
from torch.nn import Parameter
from torch_sparse import SparseTensor

from torch_geometric.nn.conv import MessagePassing
from torch_geometric.nn.dense import Linear
from torch_geometric.nn.inits import glorot, ones, reset
from torch_geometric.typing import EdgeType, Metadata, NodeType
from torch_geometric.utils import softmax


def group(xs: List[Tensor], aggr: Optional[str]) -> Optional[Tensor]:
    if len(xs) == 0:
        return None
    elif aggr is None:
        return torch.stack(xs, dim=1)
    elif len(xs) == 1:
        return xs[0]
    else:
        out = torch.stack(xs, dim=0)
        out = getattr(torch, aggr)(out, dim=0)
        out = out[0] if isinstance(out, tuple) else out
        return out


class HGTConv(MessagePassing):
    r"""
    Edited version of torch_geometric HGTConv which works with batched node features

    Args:
        in_channels (int or Dict[str, int]): Size of each input sample of every
            node type, or :obj:`-1` to derive the size from the first input(s)
            to the forward method.
        out_channels (int): Size of each output sample.
        metadata (Tuple[List[str], List[Tuple[str, str, str]]]): The metadata
            of the heterogeneous graph, *i.e.* its node and edge types given
            by a list of strings and a list of string triplets, respectively.
            See :meth:`torch_geometric.data.HeteroData.metadata` for more
            information.
        heads (int, optional): Number of multi-head-attentions.
            (default: :obj:`1`)
        group (string, optional): The aggregation scheme to use for grouping
            node embeddings generated by different relations.
            (:obj:`"sum"`, :obj:`"mean"`, :obj:`"min"`, :obj:`"max"`).
            (default: :obj:`"sum"`)
        **kwargs (optional): Additional arguments of
            :class:`torch_geometric.nn.conv.MessagePassing`.
    """
    def __init__(
        self,
        in_channels: Union[int, Dict[str, int]],
        out_channels: int,
        metadata: Metadata,
        heads: int = 1,
        group: str = "sum",
        **kwargs,
    ):
        super().__init__(aggr='add', node_dim=0, **kwargs)

        if not isinstance(in_channels, dict):
            in_channels = {node_type: in_channels for node_type in metadata[0]}

        self.in_channels = in_channels
        self.out_channels = out_channels
        self.heads = heads
        self.group = group

        self.k_lin = torch.nn.ModuleDict()
        self.q_lin = torch.nn.ModuleDict()
        self.v_lin = torch.nn.ModuleDict()
        self.a_lin = torch.nn.ModuleDict()
        self.skip = torch.nn.ParameterDict()
        for node_type, in_channels in self.in_channels.items():
            self.k_lin[node_type] = Linear(in_channels, out_channels)
            self.q_lin[node_type] = Linear(in_channels, out_channels)
            self.v_lin[node_type] = Linear(in_channels, out_channels)
            self.a_lin[node_type] = Linear(out_channels, out_channels)
            self.skip[node_type] = Parameter(torch.Tensor(1))

        self.a_rel = torch.nn.ParameterDict()
        self.m_rel = torch.nn.ParameterDict()
        self.p_rel = torch.nn.ParameterDict()
        dim = out_channels // heads
        for edge_type in metadata[1]:
            edge_type = '__'.join(edge_type)
            self.a_rel[edge_type] = Parameter(torch.Tensor(heads, dim, dim))
            self.m_rel[edge_type] = Parameter(torch.Tensor(heads, dim, dim))
            self.p_rel[edge_type] = Parameter(torch.Tensor(heads))

        self.reset_parameters()

    def reset_parameters(self):
        reset(self.k_lin)
        reset(self.q_lin)
        reset(self.v_lin)
        reset(self.a_lin)
        ones(self.skip)
        ones(self.p_rel)
        glorot(self.a_rel)
        glorot(self.m_rel)

    def forward(
        self,
        x_dict: Dict[NodeType, Tensor],
        edge_index_dict: Union[Dict[EdgeType, Tensor],
                               Dict[EdgeType, SparseTensor]]  # Support both.
    ) -> Dict[NodeType, Optional[Tensor]]:
        r"""
        Args:
            x_dict (Dict[str, Tensor]): A dictionary holding input node
                features  for each individual node type.
            edge_index_dict (Dict[str, Union[Tensor, SparseTensor]]): A
                dictionary holding graph connectivity information for each
                individual edge type, either as a :obj:`torch.LongTensor` of
                shape :obj:`[2, num_edges]` or a
                :obj:`torch_sparse.SparseTensor`.

        :rtype: :obj:`Dict[str, Optional[Tensor]]` - The output node embeddings
            for each node type.
            In case a node type does not receive any message, its output will
            be set to :obj:`None`.
        """

        H, D = self.heads, self.out_channels // self.heads

        k_dict, q_dict, v_dict, out_dict = {}, {}, {}, {}

        # Iterate over node-types:
        for node_type, x in x_dict.items():
            k_dict[node_type] = self.k_lin[node_type](x).view(-1, H, D)
            q_dict[node_type] = self.q_lin[node_type](x).view(-1, H, D)
            v_dict[node_type] = self.v_lin[node_type](x).view(-1, H, D)
            out_dict[node_type] = []

        # Iterate over edge-types:
        for edge_type, edge_index in edge_index_dict.items():
            src_type, _, dst_type = edge_type
            edge_type = '__'.join(edge_type)

            a_rel = self.a_rel[edge_type]
            k = (k_dict[src_type].transpose(0, 1) @ a_rel).transpose(1, 0)

            m_rel = self.m_rel[edge_type]
            v = (v_dict[src_type].transpose(0, 1) @ m_rel).transpose(1, 0)

            # propagate_type: (k: Tensor, q: Tensor, v: Tensor, rel: Tensor)
            out = self.propagate(edge_index, k=k, q=q_dict[dst_type], v=v,
                                 rel=self.p_rel[edge_type], size=None)
            out_dict[dst_type].append(out)

        # Iterate over node-types:
        for node_type, outs in out_dict.items():
            out = group(outs, self.group)

            if out is None:
                out_dict[node_type] = None
                continue

            out = self.a_lin[node_type](F.gelu(out))
            
            out = out.view(*x_dict[node_type].shape[:-1], -1)
            
            if out.size(-1) == x_dict[node_type].size(-1):
                alpha = self.skip[node_type].sigmoid()
                out = alpha * out + (1 - alpha) * x_dict[node_type]
            out_dict[node_type] = out

        return out_dict

    def message(self, k_j: Tensor, q_i: Tensor, v_j: Tensor, rel: Tensor,
                index: Tensor, ptr: Optional[Tensor],
                size_i: Optional[int]) -> Tensor:

        alpha = (q_i * k_j).sum(dim=-1) * rel
        alpha = alpha / math.sqrt(q_i.size(-1))
        alpha = softmax(alpha, index, ptr, size_i)
        out = v_j * alpha.view(-1, self.heads, 1)
        return out.view(-1, self.out_channels)

    def __repr__(self) -> str:
        return (f'{self.__class__.__name__}(-1, {self.out_channels}, '
                f'heads={self.heads})')


class GraphTransformer(PyTorchModule):
    def __init__(self, input_node_types: Dict[str, int],
                 inner_node_dim: int, inner_edge_types: int,
                 out_dim: int, iterations: int):
        self.save_init_params(locals())
        super().__init__()
        
        self.input_node_types = input_node_types
        self.inner_node_dim = inner_node_dim
        self.inner_edge_types = inner_edge_types
        self.out_dim = out_dim
        self.iterations = iterations
        
        self.conv = HGTConv(
            in_channels=dict(input_node_types, inner=inner_node_dim),
            out_channels=inner_node_dim,
            metadata=(
                list(input_node_types.keys()) + [Node.INNER],
                [
                    (input_node, "to", Node.INNER)
                    for input_node in input_node_types.keys()
                ] + get_inner_edge_keys(inner_edge_types)
            )
        )
        
        self.out_transform = nn.Linear(inner_node_dim, out_dim)
        self.out_pool = gnn.aggr.MeanAggregation()
        
    def forward(self, graph: gtorch.data.HeteroData) -> torch.Tensor:
        # Remove irrelevant node types
        graph = graph.node_type_subgraph(list(self.input_node_types.keys()) + [Node.INNER])
        
        # Run GNN iterations
        x_dict = graph.x_dict
        edge_index_dict = graph.edge_index_dict
        print(x_dict[Node.INNER].shape, "\n", x_dict[Node.INNER][..., :4, 0])
        for i in range(self.iterations):
            x_dict = self.conv(x_dict, edge_index_dict)
            
            # Remove input node types after first layer
            if i == 0:
                x_dict = {Node.INNER: x_dict[Node.INNER]}
                edge_index_dict = {key: val for key, val in edge_index_dict.items() if key[0] == Node.INNER and key[2] == Node.INNER}
            
            # Activation
            x_dict = {key: F.relu(val) for key, val in x_dict.items()}
            
            print(x_dict[Node.INNER].shape, "\n", x_dict[Node.INNER][..., :4, 0])
            
        x = x_dict[Node.INNER]
        x = self.out_transform(x)
        print(x.shape, "\n", x[..., :4, 0])
        x = self.out_pool(x, index=graph[Node.INNER].batch, dim=0)
        print(x.shape, "\n", x[..., :4, 0])
        return x
    
    
    
'''
class GraphModule(PyTorchModule):
    def __init__(self,
                 input_dim: int,
                 output_dim: int,
                 node_dim: int,
                 node_edge_types: int):
        self.save_init_params(locals())
        super().__init__()
        
        self.input_dim = input_dim
        self.output_dim = output_dim
        self.node_dim = node_dim
        self.node_edge_types = node_edge_types
        
        self.input_transform = nn.Linear(input_dim, node_dim)
        self.output_transform = nn.Linear(node_dim, output_dim)
        self.output_pool = gnn.aggr.MeanAggregation()
        
        self.gnn_layers = nn.ModuleList([
            gnn.RGATConv(node_dim, node_dim, node_edge_types)
            for _ in range(4)
        ])
        
    def forward(self, *input_features: torch.Tensor, graph_structure: torch.Tensor) -> torch.Tensor:
        """_summary_

        Args:
            input_features (torch.Tensor): Shape = (num_tasks, batch_size, input_dim)
            graph_structure (torch.Tensor): Shape = (num_tasks, node_count, node_count) in {0, ..., node_edge_types}

        Returns:
            torch.Tensor: Shape = (num_tasks, batch_size, output_dim)
        """
        num_tasks, node_count, _ = graph_structure.size()
        
        input_features = torch.cat(input_features, dim=-1)
        transformed_input = self.input_transform(input_features)
        
        # One for each task (separate graph), same for each node within a task
        node_features = torch.repeat_interleave(transformed_input, node_count, dim=0)
        node_task_indices = torch.repeat_interleave(ptu.arange(num_tasks), node_count)
        
        # Differs between tasks, one for each node-pair in each task
        # Referenced node indices must be incremented so they don't overlap between tasks
        orig_edge_index = (graph_structure < self.node_edge_types).nonzero().transpose(0, 1).long()
        edge_index = orig_edge_index[1:, :] + orig_edge_index[0, :].unsqueeze(0) * node_count # Increment node indices based on which task they're from
        edge_type = graph_structure[orig_edge_index[0], orig_edge_index[1], orig_edge_index[2]]
        
        x = node_features
        for gnn_layer in self.gnn_layers:
            x = gnn_layer(x, edge_index, edge_type)
            
        pooled = self.output_pool(x, index=node_task_indices, dim=0)
        output = self.output_transform(pooled)
        return output
'''

from typing import Optional, Tuple

import torch
from torch import Tensor
from torch.nn import Parameter
from torch_scatter import scatter_add
from torch_sparse import SparseTensor, fill_diag, matmul, mul
from torch_sparse import sum as sparsesum

from torch_geometric.nn.conv import MessagePassing
from torch_geometric.nn.dense.linear import Linear
from torch_geometric.nn.inits import zeros
from torch_geometric.typing import Adj, OptTensor, PairTensor
from torch_geometric.utils import add_remaining_self_loops
from torch_geometric.utils.num_nodes import maybe_num_nodes

def gcn_norm(edge_index, edge_weight=None, num_nodes=None, improved=False,
             add_self_loops=True, flow="source_to_target", dtype=None):

    fill_value = 2. if improved else 1.

    if isinstance(edge_index, SparseTensor):
        assert flow in ["source_to_target"]
        adj_t = edge_index
        if not adj_t.has_value():
            adj_t = adj_t.fill_value(1., dtype=dtype)
        if add_self_loops:
            adj_t = fill_diag(adj_t, fill_value)
        deg = sparsesum(adj_t, dim=1)
        deg_inv_sqrt = deg.pow_(-0.5)
        deg_inv_sqrt.masked_fill_(deg_inv_sqrt == float('inf'), 0.)
        adj_t = mul(adj_t, deg_inv_sqrt.view(-1, 1))
        adj_t = mul(adj_t, deg_inv_sqrt.view(1, -1))
        return adj_t

    else:
        assert flow in ["source_to_target", "target_to_source"]
        num_nodes = maybe_num_nodes(edge_index, num_nodes)

        if edge_weight is None:
            edge_weight = torch.ones((edge_index.size(1), ), dtype=dtype,
                                     device=edge_index.device)

        if add_self_loops:
            edge_index, tmp_edge_weight = add_remaining_self_loops(
                edge_index, edge_weight, fill_value, num_nodes)
            assert tmp_edge_weight is not None
            edge_weight = tmp_edge_weight

        row, col = edge_index[0], edge_index[1]
        idx = col if flow == "source_to_target" else row
        deg = scatter_add(edge_weight, idx, dim=0, dim_size=num_nodes)
        deg_inv_sqrt = deg.pow_(-0.5)
        deg_inv_sqrt.masked_fill_(deg_inv_sqrt == float('inf'), 0)
        return edge_index, deg_inv_sqrt[row] * edge_weight * deg_inv_sqrt[col]


class GCNConv(MessagePassing):
    def __init__(self, in_channels: int, out_channels: int,
                 improved: bool = False,
                 add_self_loops: bool = True, normalize: bool = True,
                 bias: bool = True, **kwargs):

        kwargs.setdefault('aggr', 'add')
        super().__init__(**kwargs)

        self.in_channels = in_channels
        self.out_channels = out_channels
        self.improved = improved
        self.add_self_loops = add_self_loops
        self.normalize = normalize

        self.lin = Linear(in_channels, out_channels, bias=False,
                          weight_initializer='glorot')

        if bias:
            self.bias = Parameter(torch.Tensor(out_channels))
        else:
            self.register_parameter('bias', None)

        self.reset_parameters()

    def reset_parameters(self):
        self.lin.reset_parameters()
        zeros(self.bias)

    def forward(self, x: Tensor, edge_index: Adj,
                edge_weight: OptTensor = None) -> Tensor:
        """"""

        if self.normalize:
            edge_index, edge_weight = gcn_norm(  # yapf: disable
                edge_index, edge_weight, x.size(self.node_dim),
                self.improved, self.add_self_loops, self.flow)

        x = self.lin(x)

        # propagate_type: (x: Tensor, edge_weight: OptTensor)
        out = self.propagate(edge_index, x=x, edge_weight=edge_weight,
                             size=None)

        if self.bias is not None:
            out += self.bias

        return out

    def message(self, x_j: Tensor, edge_weight: OptTensor) -> Tensor:
        x_feature_dims = x_j.dim() - 1
        return x_j if edge_weight is None else edge_weight.view(-1, *(1,) * x_feature_dims) * x_j

    def message_and_aggregate(self, adj_t: SparseTensor, x: Tensor) -> Tensor:
        return matmul(adj_t, x, reduce=self.aggr)


class GraphModule(PyTorchModule):
    def __init__(self,
                 input_dim: int,
                 output_dim: int,
                 node_dim: int,
                 graph_conv_iterations: int,
                 node_edge_types: int):
        self.save_init_params(locals())
        super().__init__()
        
        self.input_dim = input_dim
        self.output_dim = output_dim
        self.node_dim = node_dim
        self.graph_conv_iterations = graph_conv_iterations
        self.node_edge_types = node_edge_types
        
        self.input_transform = nn.Linear(input_dim, node_dim)
        self.output_transform = nn.Linear(node_dim, output_dim)
        self.output_pool = gnn.aggr.MeanAggregation()
        
        self.gnn_layers = nn.ModuleList([
            gnn.HeteroConv({
                (Node.INNER, f"to_{i}", Node.INNER): GCNConv(
                    node_dim, node_dim,
                    node_dim=0, add_self_loops=False
                )
                for i in range(node_edge_types)
            })
            for _ in range(graph_conv_iterations)
        ])
        
    def forward(self, *input_features: torch.Tensor, graph_structure: torch.Tensor) -> torch.Tensor:
        """_summary_

        Args:
            input_features (torch.Tensor): Shape = (num_tasks, batch_size, input_dim)
            graph_structure (torch.Tensor): Shape = (num_tasks, node_count, node_count) in {0, ..., node_edge_types}

        Returns:
            torch.Tensor: Shape = (num_tasks, batch_size, output_dim)
        """
        num_tasks, node_count, _ = graph_structure.size()
        
        input_features = [x for x in input_features if x is not None]
        input_features = torch.cat(input_features, dim=-1)
        transformed_input = F.relu(self.input_transform(input_features))
        
        # One for each task (separate graph), same for each node within a task
        node_features = torch.repeat_interleave(transformed_input, node_count, dim=0)
        node_task_indices = torch.repeat_interleave(ptu.arange(num_tasks), node_count)
        
        # Differs between tasks, one for each node-pair in each task
        # Referenced node indices must be incremented so they don't overlap between tasks
        orig_edge_index = (graph_structure < self.node_edge_types).nonzero().transpose(0, 1).long()
        edge_index = orig_edge_index[1:, :] + orig_edge_index[0, :].unsqueeze(0) * node_count # Increment node indices based on which task they're from
        edge_type = graph_structure[orig_edge_index[0], orig_edge_index[1], orig_edge_index[2]]
        
        x_dict = {Node.INNER: node_features}
        edge_index_dict = {
            (Node.INNER, f"to_{i}", Node.INNER): edge_index[:, (edge_type == i).nonzero()[:, 0].long()]
            for i in range(self.node_edge_types)
        }
        
        for gnn_layer in self.gnn_layers:
            x_dict = gnn_layer(x_dict, edge_index_dict)
            x_dict = {key: F.relu(val) for key, val in x_dict.items()}
            
        pooled = self.output_pool(x_dict[Node.INNER], index=node_task_indices, dim=0)
        output = self.output_transform(pooled)
        return output